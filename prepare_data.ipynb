{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare grooming and nongrooming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f81e597520dd>:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platform: Windows-10-10.0.19041-SP0 Mozart\n",
      "4.5.1\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import shutil\n",
    "# from multiprocessing import Pool, current_process\n",
    "\n",
    "import random\n",
    "import math \n",
    "from tqdm.autonotebook import tqdm\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from time import time\n",
    "import platform\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from re import sub             \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi']= 120\n",
    "\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "pd.set_option('display.float_format', '{:,.5f}'.format)\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "\n",
    "_platform = platform.platform()\n",
    "print('platform:', _platform, platform.node())\n",
    "if 'Linux' in _platform: # linux\n",
    "    rat_path = '/home/ece/rat_data/'\n",
    "    tsn_path = '/home/ece/tsn_data/'\n",
    "    \n",
    "elif 'macOS' in _platform: # MAC OS X\n",
    "    rat_path = '/Users/cclee/rat_data/'\n",
    "    tsn_path = '/Users/cclee/tsn_data/'     \n",
    "elif 'Windows' in _platform: # Windows\n",
    "    if platform.node()=='Mozart':\n",
    "        rat_path = 'e:/rat_data/'\n",
    "        tsn_path = 'e:/tsn_data/' \n",
    "    else:\n",
    "        rat_path = 'd:/rat_data/'   \n",
    "        tsn_path = 'd:/tsn_data/' \n",
    "  \n",
    "path_rat = pathlib.Path(rat_path)\n",
    "path_tsn = pathlib.Path(tsn_path)\n",
    "path_new_grooming = path_rat.joinpath('new_grooming')\n",
    "\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all  [921111, 921112, 921113, 921216, 921217, 921218, 930203, 930204, 930205, 930217, 930218, 930219, 930302, 930303, 930304, 930309, 930310, 930311, 930316, 930317, 930318, 930323, 930324, 930325, 930330]\n",
      "remove_lst  [921112, 921113, 921217, 921218, 930204, 930205, 930218, 930219, 930303, 930304, 930310, 930311, 930317, 930318, 930324, 930325]\n",
      "rat_lst  [921111, 921216, 930203, 930217, 930302, 930309, 930316, 930323, 930330]\n",
      "9 [921111, 921216, 930203, 930217, 930302, 930309, 930316, 930323, 930330]\n"
     ]
    }
   ],
   "source": [
    "finished_lst = [921111, 930302, 930316, 921216, 930203, 930217] \n",
    "\n",
    "def get_rat_lst(allrat=True):\n",
    "    rat_lst = []\n",
    "    if allrat:\n",
    "        all_rat_set = set()\n",
    "        csv_lst = sorted(path_new_grooming.glob('9*.csv'))\n",
    "        for csvf in csv_lst:\n",
    "            tok = csvf.stem.split('_')\n",
    "            rat_date = int(tok[0])\n",
    "            all_rat_set.add(rat_date)\n",
    "        \n",
    "        rat_lst = list(all_rat_set)\n",
    "        rat_lst.sort()\n",
    "        \n",
    "        print('all ', rat_lst)\n",
    "        remove_lst = []\n",
    "        for i in range(len(rat_lst)-1):\n",
    "            if rat_lst[i]+1==rat_lst[i+1]:\n",
    "                remove_lst.append(rat_lst[i+1])\n",
    "          \n",
    "        print('remove_lst ', remove_lst)\n",
    "        for r in remove_lst:\n",
    "            rat_lst.remove(r)    \n",
    "                \n",
    "#         for r in finished_lst:\n",
    "#             rat_lst.remove(r)                        \n",
    "        \n",
    "    print('rat_lst ', rat_lst)\n",
    "    return rat_lst\n",
    "\n",
    "rat_lst = get_rat_lst()\n",
    "print(len(rat_lst), rat_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1. copy grooming/non-grooming mp4 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[930330, 930331, 930332]\n",
      "e:\\tsn_data\\930330\\frames\n",
      "rat_gm_lst 106\n",
      "copy  e:\\rat_data\\930330-base-1d 934\n"
     ]
    }
   ],
   "source": [
    "rat_lst = [930330] #get_rat_lst() #[921111, 930302, 930316, 921216, 930203] #930217\n",
    "\n",
    "def copy_clips(copy=False):\n",
    "    rat_gm_lst = []\n",
    "    csv_lst = sorted(path_new_grooming.glob('9*.csv'))\n",
    "    for csvf in csv_lst:\n",
    "        tok = csvf.stem.split('_')\n",
    "        rat_date = int(tok[0])\n",
    "        if rat_date in rat_date_lst:\n",
    "            rat_gm_lst.append(tok[0]+'_'+tok[1])\n",
    "\n",
    "    print('rat_gm_lst', len(rat_gm_lst))\n",
    "    #     print(rat_gm_lst)\n",
    "\n",
    "    clip_dir_lst = [x for x in path_rat.iterdir() if x.is_dir() and x.name[0]=='9' and int(x.name[:6]) in rat_date_lst]\n",
    "    clip_dir_lst = sorted(clip_dir_lst)\n",
    "    if len(clip_dir_lst)==0:\n",
    "        print('cannot find rat in rat_data')\n",
    "\n",
    "    grooming_lst = []\n",
    "    nongrooming_lst = []\n",
    "    for clip_dir in clip_dir_lst:\n",
    "        clip_lst = sorted(clip_dir.glob('*.mp4'))\n",
    "        print('copy ', clip_dir, len(clip_lst))\n",
    "        for clip in clip_lst:\n",
    "            tok = clip.stem.split('_')\n",
    "            clip_name = tok[0]+'_'+tok[1]\n",
    "    #             print(clip_name)\n",
    "            if clip_name in rat_gm_lst:\n",
    "                grooming_lst.append(str(clip)+'\\n')\n",
    "                if copy:\n",
    "                    shutil.copyfile(clip, path_rat_grooming.joinpath(clip.name) )\n",
    "            else:\n",
    "                nongrooming_lst.append(str(clip)+'\\n')\n",
    "                if copy:\n",
    "                    shutil.copyfile(clip, path_rat_nongrooming.joinpath(clip.name) )\n",
    "    \n",
    "    return grooming_lst, nongrooming_lst\n",
    "\n",
    "for rat in rat_lst:\n",
    "    outpath = path_tsn.joinpath('{}'.format(rat))\n",
    "    try:\n",
    "        if not outpath.exists():\n",
    "            outpath.mkdir() \n",
    "    except Exception as ex:\n",
    "        print(ex.__class__.__name__)\n",
    "\n",
    "    path_frames = outpath.joinpath('frames')\n",
    "#     path_rat_grooming = outpath.joinpath('grooming')\n",
    "#     path_rat_nongrooming = outpath.joinpath('nongrooming')\n",
    "    if not path_frames.exists():\n",
    "        path_frames.mkdir()   \n",
    "#     if path_rat_grooming.exists():\n",
    "#         shutil.rmtree(str(path_rat_grooming))\n",
    "#         path_rat_grooming.mkdir()   \n",
    "#     if path_rat_nongrooming.exists():\n",
    "#         shutil.rmtree(str(path_rat_nongrooming))\n",
    "#         path_rat_nongrooming.mkdir()\n",
    "\n",
    "\n",
    "    rat_date_lst = [ rat +i for i in range(3)]\n",
    "    print(rat_date_lst)\n",
    "    print(path_frames)\n",
    "#     print(path_rat_grooming)\n",
    "#     print(path_rat_nongrooming)\n",
    "    \n",
    "    grooming_lst, nongrooming_lst = copy_clips(copy=False)\n",
    "    \n",
    "    fname = outpath.joinpath('grooming_lst.txt')\n",
    "    with open(fname, 'w') as f:\n",
    "        f.writelines( grooming_lst )\n",
    "        \n",
    "    fname = outpath.joinpath('nongrooming_lst.txt')\n",
    "    with open(fname, 'w') as f:\n",
    "        f.writelines( nongrooming_lst )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step2. generate optical flow images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/qijiezhao/py-denseflow\n",
    "\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "# from multiprocessing import Pool\n",
    "\n",
    "# from IPython import embed #to debug\n",
    "\n",
    "import imageio\n",
    "\n",
    "\n",
    "def ToImg(raw_flow,bound):\n",
    "    '''\n",
    "    this function scale the input pixels to 0-255 with bi-bound\n",
    "    :param raw_flow: input raw pixel value (not in 0-255)\n",
    "    :param bound: upper and lower bound (-bound, bound)\n",
    "    :return: pixel value scale from 0 to 255\n",
    "    '''\n",
    "    flow=raw_flow\n",
    "    flow[flow>bound]=bound\n",
    "    flow[flow<-bound]=-bound\n",
    "    flow-=-bound\n",
    "    flow*=(255/float(2*bound))\n",
    "    return flow\n",
    "\n",
    "def save_flows(flows,image,save_dir,num,bound):\n",
    "    '''\n",
    "    To save the optical flow images and raw images\n",
    "    :param flows: contains flow_x and flow_y\n",
    "    :param image: raw image\n",
    "    :param save_dir: save_dir name (always equal to the video id)\n",
    "    :param num: the save id, which belongs one of the extracted frames\n",
    "    :param bound: set the bi-bound to flow images\n",
    "    :return: return 0\n",
    "    '''\n",
    "    #rescale to 0~255 with the bound setting\n",
    "    flow_x=ToImg(flows[...,0],bound).astype(np.uint8)\n",
    "    flow_y=ToImg(flows[...,1],bound).astype(np.uint8)\n",
    "#    if not os.path.exists(os.path.join(data_root,new_dir,save_dir)):\n",
    "#        os.makedirs(os.path.join(data_root,new_dir,save_dir))\n",
    "\n",
    "    #save the image\n",
    "    save_img=save_dir.joinpath('img_{:05d}.jpg'.format(num))\n",
    "#    scipy.misc.imsave(save_img,image)\n",
    "    cv2.imwrite(str(save_img), image)\n",
    "\n",
    "    #save the flows\n",
    "    save_x=save_dir.joinpath('flow_x_{:05d}.jpg'.format(num))\n",
    "    save_y=save_dir.joinpath('flow_y_{:05d}.jpg'.format(num))\n",
    "    flow_x_img=Image.fromarray(flow_x)\n",
    "    flow_y_img=Image.fromarray(flow_y)\n",
    "    imageio.imwrite(save_x,flow_x_img)\n",
    "    imageio.imwrite(save_y,flow_y_img)\n",
    "    \n",
    "    if num==2:\n",
    "        shutil.copyfile(save_x, save_dir.joinpath('flow_x_00001.jpg'))\n",
    "        shutil.copyfile(save_y, save_dir.joinpath('flow_y_00001.jpg'))\n",
    "        \n",
    "#     cv2.imwrite(str(save_x), flow_x_img)\n",
    "#     cv2.imwrite(str(save_y), flow_y_img)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all  [921111, 921112, 921113, 921216, 921217, 921218, 930203, 930204, 930205, 930217, 930218, 930219, 930302, 930303, 930304, 930309, 930310, 930311, 930316, 930317, 930318, 930323, 930324, 930325, 930330]\n",
      "remove_lst  [921112, 921113, 921217, 921218, 930204, 930205, 930218, 930219, 930303, 930304, 930310, 930311, 930317, 930318, 930324, 930325]\n",
      "rat_lst  [930217, 930309, 930323, 930330]\n",
      "e:\\tsn_data\\930217\\frames\n",
      "clip_gm_lst 579\n",
      "clip_nongm_lst 2456\n",
      "calculate optical flow for grooming list\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb09f6a19ae4bfa832089887a807822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=579.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calculate optical flow for non-grooming list\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff3434952bb4b75b9ec9d567390b611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2456.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\tsn_data\\930309\\frames\n",
      "clip_gm_lst 515\n",
      "clip_nongm_lst 2495\n",
      "calculate optical flow for grooming list\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464b2ce622c2412f8a04f29d79af3781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=515.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calculate optical flow for non-grooming list\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8055729ffb43f28cd0f83a182b8048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2495.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\tsn_data\\930323\\frames\n",
      "clip_gm_lst 521\n",
      "clip_nongm_lst 2420\n",
      "calculate optical flow for grooming list\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdf5fca9d044f1c87eadbbcd971a13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=521.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calculate optical flow for non-grooming list\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790c896e8e664835bfcc268348fc8a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2420.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\tsn_data\\930330\\frames\n",
      "clip_gm_lst 106\n",
      "clip_nongm_lst 828\n",
      "calculate optical flow for grooming list\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd5863affde49c2b4fb0033aa2cc76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=106.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calculate optical flow for non-grooming list\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7f7b8f05ad4382a17ff486afdcbbbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=828.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bound=20\n",
    "rat_lst = get_rat_lst() # [921111, 930302, 930316, 921216, 930203, 930217]\n",
    "\n",
    "def calc_optical_flow(fname, out_dir):\n",
    "    \n",
    "    cap = cv2.VideoCapture(str(fname))\n",
    "\n",
    "    bOpenVideo = cap.isOpened()\n",
    "    if bOpenVideo == False:\n",
    "        print('Open Video failed')\n",
    "    else:\n",
    "        fcount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT ))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))    \n",
    "#         print('%s: fps = %d, w %d, h %d, count %d' % (clip.name, fps, width, height, fcount))\n",
    "\n",
    "\n",
    "        ret, frame1 = cap.read()\n",
    "        if ret==False:\n",
    "            print('cap.read() error, frame:')\n",
    "            return\n",
    "        \n",
    "        save_img=out_dir.joinpath('img_{:05d}.jpg'.format(1))\n",
    "        cv2.imwrite(str(save_img), frame1)\n",
    "        \n",
    "        prvs_fm = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "#         hsv = np.zeros_like(frame1)\n",
    "#         hsv[...,1] = 255\n",
    "\n",
    "        i = 2\n",
    "#         pbar = tqdm(total=fcount-1, ascii=True) \n",
    "        if platform.node()=='Mozart':\n",
    "            cuMat1 = cv2.cuda_GpuMat()\n",
    "            cuMat2 = cv2.cuda_GpuMat()\n",
    "        while(1):\n",
    "            ret, frame2 = cap.read()\n",
    "            if ret==False:\n",
    "                break\n",
    "\n",
    "            next_fm = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            if platform.node()=='Mozart':\n",
    "                cuMat1.upload(prvs_fm)\n",
    "                cuMat2.upload(next_fm)\n",
    "                optical_flow = cv2.cuda_OpticalFlowDual_TVL1.create()\n",
    "                cuFlow = optical_flow.calc(cuMat1, cuMat2, None)\n",
    "                flow = cuFlow.download()    \n",
    "            else:\n",
    "                optical_flow = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "                flow = optical_flow.calc(prvs_fm, next_fm, None)\n",
    "\n",
    "#             mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "#             hsv[...,0] = ang*180/np.pi/2\n",
    "#             hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "#             rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "#             frame_name = out_dir.joinpath('img_{:05d}.jpg'.format(i))\n",
    "#             opf_name = out_dir.joinpath('flow_{:05d}.jpg'.format(i))\n",
    "#             cv2.imwrite(str(frame_name), frame2)\n",
    "#             cv2.imwrite(str(opf_name), rgb)\n",
    "            \n",
    "            save_flows(flow, frame2, out_dir, i, bound)\n",
    "\n",
    "            prvs_fm = next_fm\n",
    "            i +=1\n",
    "#             pbar.update(1)\n",
    "            \n",
    "#         pbar.close()\n",
    "        \n",
    "    cap.release()   \n",
    "        \n",
    "        \n",
    "for rat in rat_lst:\n",
    "    outpath = path_tsn.joinpath('{}'.format(rat))\n",
    "    if not outpath.exists():\n",
    "        print('folder not exists', outpath)\n",
    "        break \n",
    "    \n",
    "\n",
    "    path_frames = outpath.joinpath('frames')\n",
    "#     path_rat_grooming = outpath.joinpath('grooming')\n",
    "#     path_rat_nongrooming = outpath.joinpath('nongrooming')\n",
    "  \n",
    "    print(path_frames)\n",
    "#     print(path_rat_grooming)\n",
    "#     print(path_rat_nongrooming)\n",
    "    \n",
    "#     clip_gm_lst = sorted(path_rat_grooming.glob('9*.mp4'))\n",
    "    fname = outpath.joinpath('grooming_lst.txt')\n",
    "    with open(fname) as f:\n",
    "        clip_gm_lst = f.readlines()\n",
    "    print('clip_gm_lst',len(clip_gm_lst))\n",
    "\n",
    "#     clip_nongm_lst = sorted(path_rat_nongrooming.glob('9*.mp4'))\n",
    "    fname = outpath.joinpath('nongrooming_lst.txt')\n",
    "    with open(fname) as f:\n",
    "        clip_nongm_lst = f.readlines()\n",
    "    print('clip_nongm_lst',len(clip_nongm_lst))\n",
    "\n",
    "    print('calculate optical flow for grooming list')\n",
    "    pbar = tqdm(total=len(clip_gm_lst), ascii=True)\n",
    "    for clip in clip_gm_lst:\n",
    "        cpath = pathlib.Path(clip)\n",
    "        vid_name = cpath.stem.split('.')[0]\n",
    "        clip_dir = path_frames.joinpath('Grooming_'+vid_name)\n",
    "        if  clip_dir.exists():\n",
    "            shutil.rmtree(str(clip_dir))\n",
    "        clip_dir.mkdir()  \n",
    "        \n",
    "\n",
    "        calc_optical_flow(clip, clip_dir )            \n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()    \n",
    "\n",
    "    print('calculate optical flow for non-grooming list')\n",
    "    pbar = tqdm(total=len(clip_nongm_lst), ascii=True)\n",
    "    for clip in clip_nongm_lst:\n",
    "        cpath = pathlib.Path(clip)\n",
    "        vid_name = cpath.stem.split('.')[0]\n",
    "        clip_dir = path_frames.joinpath('Nongrooming_'+vid_name)\n",
    "        if  clip_dir.exists():\n",
    "            shutil.rmtree(str(clip_dir))\n",
    "        clip_dir.mkdir()   \n",
    "\n",
    "        calc_optical_flow(clip, clip_dir )            \n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# frame1 = (cv2.imread('basketball1.png', cv2.IMREAD_GRAYSCALE))\n",
    "# frame2 = (cv2.imread('basketball2.png', cv2.IMREAD_GRAYSCALE))\n",
    "\n",
    "# nvof = cv2.cuda_NvidiaOpticalFlow_1_0.create(frame1.shape[1], frame1.shape[0], 5, False, False, False, 0)\n",
    "\n",
    "# flow = nvof.calc(frame1, frame2, None)\n",
    "\n",
    "# flowUpSampled = nvof.upSampler(flow[0], frame1.shape[1], frame1.shape[0], nvof.getGridSize(), None)\n",
    "\n",
    "# cv2.writeOpticalFlow('OpticalFlow.flo', flowUpSampled)\n",
    "\n",
    "# nvof.collectGarbage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image resize to (340, 256)\n",
    "## copy to newframes dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_newframes e:\\tsn\\newframes\n",
      "e:\\tsn\\921111\\frames\n",
      "oldframe_dir_lst 3207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45fd1514a38495589e05a5b67219d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3207.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\tsn\\930302\\frames\n",
      "oldframe_dir_lst 3093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4aaddabab84f9d8b6c8ed7ecc797f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3093.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\tsn\\930316\\frames\n",
      "oldframe_dir_lst 3263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca410418bcb74c1e888af1e705a8587a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3263.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\tsn\\921216\\frames\n",
      "oldframe_dir_lst 2986\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e813ce857947a88a7108553d75054e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2986.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\tsn\\930203\\frames\n",
      "oldframe_dir_lst 3026\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb61e24fdde4f3796d1f0d99ce7aa6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3026.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\tsn\\930217\\frames\n",
      "oldframe_dir_lst 3035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1360358fe6b441508ba868c5ba7307d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3035.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rat_lst = [921111, 930302, 930316, 921216, 930203, 930217]\n",
    "\n",
    "path_newframes = path_tsn.joinpath('newframes')\n",
    "print('path_newframes', path_newframes)\n",
    "if not path_newframes.exists():\n",
    "    print('create path_newframes ')\n",
    "    path_newframes.mkdir()\n",
    "        \n",
    "for rat in rat_lst:\n",
    "    path_frames = path_tsn.joinpath(str(rat), 'frames')\n",
    "    print(path_frames)\n",
    "    if not path_frames.exists():\n",
    "        print('cannot find path ', path_frames)\n",
    "        break\n",
    "        \n",
    "    oldframe_dir_lst = [x for x in path_frames.iterdir() if x.is_dir()]\n",
    "    print('oldframe_dir_lst', len(oldframe_dir_lst))\n",
    "    pbar = tqdm(total=len(oldframe_dir_lst), ascii=True)\n",
    "    for dd in oldframe_dir_lst:\n",
    "        new_frame_dir = path_newframes.joinpath(dd.name)\n",
    "        new_frame_dir.mkdir()\n",
    "        image_lst = dd.glob('*.jpg')\n",
    "        for img in image_lst:\n",
    "            pic = cv2.imread(str(img))\n",
    "            pic = cv2.resize(pic, (340, 256), interpolation=cv2.INTER_CUBIC)\n",
    "            cv2.imwrite(str(new_frame_dir.joinpath(img.name)), pic)\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3. generate train_lst and val_lst files\n",
    "## Rat dependent\n",
    "The user-dependent (UD) training methods require training data from each user, from which a user-specific model is generated. \n",
    "\n",
    "The UI training methods require training data from multiple participants and a generalized model, or a ‘UI’ model, is generated such that it can be applied to unseen users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all  [921111, 921112, 921113, 921216, 921217, 921218, 930203, 930204, 930205, 930217, 930218, 930219, 930302, 930303, 930304, 930309, 930310, 930311, 930316, 930317, 930318, 930323, 930324, 930325, 930330]\n",
      "remove_lst  [921112, 921113, 921217, 921218, 930204, 930205, 930218, 930219, 930303, 930304, 930310, 930311, 930317, 930318, 930324, 930325]\n",
      "rat_lst  [921111, 921216, 930203, 930217, 930302, 930309, 930316, 930323, 930330]\n",
      "d:\\tsn_data\\921111\\frames\n",
      "cannot find path  d:\\tsn_data\\921111\\frames\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a335b4e6e8a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mdf_test_lst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train_lst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test_lst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \"\"\"\n\u001b[1;32m--> 271\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    272\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No objects to concatenate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "SPLIT = 1\n",
    "SEED = 43\n",
    "\n",
    "rat_lst = get_rat_lst() # [921111, 930302, 930316, 921216, 930203, 930217]\n",
    "\n",
    "df_train_lst = []\n",
    "df_test_lst = []\n",
    "\n",
    "\n",
    "for rat in rat_lst:\n",
    "    path_frames = path_tsn.joinpath(str(rat), 'frames')\n",
    "    print(path_frames)\n",
    "    if not path_frames.exists():\n",
    "        print('cannot find path ', path_frames)\n",
    "        break    \n",
    "\n",
    "    grooming_train_lst = [str(x) for x in path_frames.iterdir() if x.is_dir() and x.name[0]=='G' and str(rat) in x.name]\n",
    "    non_grooming_train_lst = [str(x) for x in path_frames.iterdir() if x.is_dir() and x.name[0]=='N' and str(rat) in x.name]\n",
    "    \n",
    "    print('grooming_train_lst', len(grooming_train_lst))\n",
    "    print('non_grooming_train_lst', len(non_grooming_train_lst))\n",
    "    x = grooming_train_lst.copy()\n",
    "    \n",
    "    x.extend(non_grooming_train_lst)\n",
    "    print('total x', len(x))\n",
    "    \n",
    "    y = list(np.ones(len(grooming_train_lst), np.int8))\n",
    "    y.extend(list(np.zeros(len(non_grooming_train_lst), np.int8)))\n",
    "    \n",
    "    print('total y',len(y), 'sum y',sum(y), sum(y)/len(y))\n",
    "    \n",
    "    skf = StratifiedShuffleSplit(n_splits=SPLIT, random_state=SEED, test_size=0.2)\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index), 'SUM:', len(train_index)+len(test_index))\n",
    "\n",
    "    df = pd.DataFrame({'x':x, 'y':y}) \n",
    "    print(df)\n",
    "    df_train = df.iloc[train_index]\n",
    "    print('df_train', df_train.shape)\n",
    "    \n",
    "    # nongroom 取1.2倍的grooming 數量\n",
    "    num_train_groom = sum(df_train['y'])\n",
    "    num_train_nongroom = int(num_train_groom * 1.2)\n",
    "    \n",
    "    df_train_groom = df_train[df_train['y']==1]\n",
    "    df_train_nongroom1 = df_train[df_train['y']==0]\n",
    "    df_train_nongroom2 = df_train_nongroom1.sample(n=num_train_nongroom, random_state=SEED)\n",
    "    df_train_nongroom3 = df_train_nongroom1.drop(df_train_nongroom2.index)\n",
    "    \n",
    "    df_train = df_train_groom.append(df_train_nongroom2)\n",
    "    df_train = df_train.sample(frac=1, random_state=SEED)\n",
    "    \n",
    "    print('df_train: sum of 1', sum(df_train['y']), sum(df_train['y'])/len(df_train))\n",
    "    print('df_train_nongroom1 (origin)', len(df_train_nongroom1))\n",
    "    print('df_train_nongroom2', len(df_train_nongroom2))\n",
    "    print('df_train_nongroom3 (rest)', len(df_train_nongroom3))\n",
    "    print('df_train', len(df_train))\n",
    "    \n",
    "    df_test = df.iloc[test_index]\n",
    "    print('df_test', df_test.shape)\n",
    "    \n",
    "    # nongroom 取1.2倍的grooming 數量\n",
    "    num_test_groom = sum(df_test['y'])\n",
    "    num_test_nongroom = int(num_test_groom * 1.2)\n",
    "    \n",
    "    df_test_groom = df_test[df_test['y']==1]\n",
    "    df_test_nongroom1 = df_test[df_test['y']==0]\n",
    "    df_test_nongroom2 = df_test_nongroom1.sample(n=num_test_nongroom, random_state=SEED)\n",
    "    df_test_nongroom3 = df_test_nongroom1.drop(df_test_nongroom2.index)\n",
    "    \n",
    "    df_test = df_test_groom.append(df_test_nongroom2)\n",
    "    df_test = df_test.sample(frac=1, random_state=SEED)\n",
    "    \n",
    "    \n",
    "    print('df_test: sum of 1', sum(df_test['y']), sum(df_test['y'])/len(df_test))\n",
    "    print('df_test (after append)', len(df_test))\n",
    "    print('df_test: sum of 1', sum(df_test['y']), sum(df_test['y'])/len(df_test))\n",
    " \n",
    "    df_train_lst.append(df_train)\n",
    "    df_test_lst.append(df_test)\n",
    "    \n",
    "df_train = pd.concat(df_train_lst) \n",
    "df_test = pd.concat(df_test_lst)\n",
    "\n",
    "#### output train file list\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "frame_count_lst = []\n",
    "for row in df_train.itertuples():\n",
    "    path_folder = pathlib.Path(row.x)\n",
    "    img_lst = list(path_folder.glob('img*.jpg'))\n",
    "    frame_count_lst.append(len(img_lst))\n",
    "\n",
    "ss = pd.Series(frame_count_lst)    \n",
    "df_train.insert(1, 'count', ss)\n",
    "print('df_train')\n",
    "display(df_train)\n",
    "\n",
    "path_tsn_data = path_tsn.joinpath('data')\n",
    "if not path_tsn_data.exists():\n",
    "    path_tsn_data.mkdir() \n",
    "fname = path_tsn_data.joinpath('train_lst.txt')\n",
    "df_train.to_csv(fname, header=False, index = False, sep = ' ')\n",
    "\n",
    "###########################################\n",
    "#### output test file list\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "frame_count_lst = []\n",
    "for row in df_test.itertuples():\n",
    "    path_folder = pathlib.Path(row.x)\n",
    "    img_lst = list(path_folder.glob('img*.jpg'))\n",
    "    frame_count_lst.append(len(img_lst))\n",
    "\n",
    "ss = pd.Series(frame_count_lst)    \n",
    "df_test.insert(1, 'count', ss)\n",
    "print('df_test')\n",
    "display(df_test)\n",
    "\n",
    "fname = path_tsn_data.joinpath('val_lst.txt')\n",
    "df_test.to_csv(fname, header=False, index = False, sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    }
   ],
   "source": [
    "path_folder = pathlib.Path('/Users/cclee/tsn/930217/frames/Nongrooming_930219_L32905_002725')\n",
    "img_lst = list(path_folder.glob('img*.jpg'))\n",
    "print(len(img_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
